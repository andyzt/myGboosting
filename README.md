# myGboosting
Простая реализация градиентного бустинга. Работает с задачами регрессии, использует метрику MSE.

## Использование

Утилита предполагает вызов из командной строки. 
В качестве обучающей и тестовой выборки используются стандартные файлы csv. 
Утилита имеет 2 режима работы: обучение (fit) и применение (predict).

### Сборка проекта
перейти в каталог src, создать в нем каталог build, перейти в него и выполнить следующие команды:
    
    cmake ..
    make -j4

при этом на компьютере должны быть установлены библиотеки Open MP и protobuf. 

### Обучение

Формат запуска:

`myGboosting fit <file path> [optional parameters]`

`<file path>` - путь к csv файлу, содержащему обучающую выборку
#### Параметры:

| Параметр       | Описание                                                                            | Значение по умолчанию |
|----------------|-------------------------------------------------------------------------------------|-----------------------|
| column_names   | путь к файлу, содержащему названия столбцов обучающей выборки                       |                       |
| model-path     | имя файла, в который будет сохранена обученная модель                               |                       |
| output-path    | имя файла, в который будут сохранены прогнозы обученной модели на обучающей выборке |                       |
| target         | номер колонки, которая содержит значение целевой переменной                         | последняя колонка     |
| nthread        | число параллельных потоков, используемых для обучения                               |          1            |
| delimiter      | разделитель, используемый в csv-файлах                                              |          ,            |
| has-header     | имеет ли входной csv-файл заголовок с названиями столбцов                           |        false          |
| iterations     | максимальное количество деревьев в модели                                           |        100            |
| learning-rate  | темп обучения модели                                                                |        1.0            |
| depth          | глубина решающего дерева                                                            |        6              |
| max_bins       | количество сплитов в гистограмме для числовых признаков (от 1 до 255)               |        10             |
| verbose        | степень подробности выводимой в консоль информации                                  |        0              |
| sample_rate    | вероятность сэмплинга строк для каждого дерева (какую часть датасета использовать)  |        0.66           |
| min_leaf_count | минимальное количество объектов в листовой вершине                                  |        10             |


### Применение

Формат запуска:

myGboosting predict \<file path> [optional parameters]

\<file path> - путь к csv файлу, содержащему тестовую выборку
#### Параметры:

| Параметр       | Описание                                                                            | Значение по умолчанию |
|----------------|-------------------------------------------------------------------------------------|-----------------------|
| column_names   | путь к файлу, содержащему названия столбцов тестовой выборки                        |                       |
| model-path     | имя файла, из которого будет считана обученная модель                               |                       |
| output-path    | имя файла, в который будут сохранены прогнозы модели на тестовой выборке            |                       |
| delimiter      | разделитель, используемый в csv-файлах                                              |           ,           |
| has-header     | имеет ли входной csv-файл заголовок с названиями столбцов                           |         false         |
| verbose        | степень подробности выводимой в консоль информации                                  |           0           |


### Архитектура 

- Используются Oblivious Decision trees и гистограммы признаков
- Параллелизация при обучении происходит при выборе оптимального сплита c помощью библиотеки Open MP
- для сохранения и загрузки моделей используется библиотека Protobuf

### Результаты

Модель проверялась на наборе данных Higgs, была взята train выборка (250000 сэмплов) 
и поделена на train (20000) и тест (50000). Поскольку последняя колонка - 
это бинарная классификация, то предсказывалась предпоследняя (вес частицы).

#### Параметры запуска:
LightGBM

    time ./lightgbm objective=mse data=../../myGboosting/testing/datasets/Higgs/train.csv num_threads=1 num_iterations=400 max_bin=255 bagging_fraction=0.5 feature_fraction=1.0 bagging_freq=1 num_leaves=64 learning_rate=0.5 label=31

myGboosting

    time ./myGboosting fit  ../testing/datasets/Higgs/train.csv --output=model.pb --iterations=400 --depth=6 --learning-rate=0.5 --sample-rate=0.5 --max_bins=255 --nthreads=1

#### Результаты на 1 потоке
Модель проверялась на ноутбуке Macbook Pro 15 2015. Поэтому в наличии есть 4 реальных ядра и 8 виртуальных.
| Решение   | Depth | Row sampling | Кол-во деревьев | Learning Rate |Время   | Память | MSE Train | MSE Test      | 
|-----------|-------|--------------|-----------------|---------------|--------|--------|-----------|---------------|
| LightGBM  |   6   |     0.5      |       400       |      0.5      |13.352s |        | 0.6469    | 1.88662       |
|myGboosting|   6   |     0.5      |       400       |      0.5      |12.062s |        | 1.11156   | 1.44719       |

#### Результаты в многопоточном режиме (время)

| Решение   | 1 поток |2 потока |4 потока |6 потоков|8 потоков|
|-----------|---------|---------|---------|---------|-------- |
| LightGBM  | 13.352s | 10.404s | 8.727s  | 9.070s  | 9.766s  |      
|myGboosting| 12.062s | 8.915s  | 7.604s  | 7.304s  | 7.313s  |

Видно, что после 4 потоков производительность почти не растет.
Видимо нужна более серьезная задача.


### Используемые библиотеки

1) https://github.com/ben-strasser/fast-cpp-csv-parser
2) https://github.com/Taywee/args
3) https://developers.google.com/protocol-buffers/
4) https://www.openmp.org

